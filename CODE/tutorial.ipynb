{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Hawkes Process Estimation - Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Hawkes as hk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PREPROCESSING.hawkes import hawkes_simulations, hawkes_simulation\n",
    "from PREPROCESSING.hyperparameters import hyper_params_simulation\n",
    "from PREPROCESSING.discretisation import discretise\n",
    "import VARIABLES.variables as var\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset generation\n",
    "\n",
    "# Intensity Decay Parameter (β) = U(p = 1, q = 3)\n",
    "# Branching Ratio (η) = U(a = 0.05, b = 0.8)\n",
    "# Expected Activity (E) = 500\n",
    "# Time Horizon (T) = 100\n",
    "# Interval Length (∆) = 1\n",
    "# Training processes = 100_000\n",
    "\n",
    "# Hawkes process hyper-parameters generation\n",
    "train_params, train_alpha, train_beta, train_mu = hyper_params_simulation(filename=\"train_hawkes_hyperparams.csv\")\n",
    "\n",
    "# Hawkes processes simulations\n",
    "train_simulated_events_seqs = hawkes_simulations(train_mu, train_alpha, train_beta, filename='train_hawkes_simulations.csv')\n",
    "\n",
    "# Discrétiser les processus de Hawkes\n",
    "#train_discret_simulated_events_seqs = discretise(train_simulated_events_seqs, filename='train_binned_hawkes_simulations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating dataset generation\n",
    "\n",
    "# Intensity Decay Parameter (β) = U(p = 1, q = 3)\n",
    "# Branching Ratio (η) = U(a = 0.05, b = 0.8)\n",
    "# Expected Activity (E) = 500\n",
    "# Time Horizon (T) = 100\n",
    "# Interval Length (∆) = 1\n",
    "# Training processes = 30_000\n",
    "\n",
    "# Hawkes process hyper-parameters generation\n",
    "val_params, val_alpha, val_beta, val_mu = hyper_params_simulation(filename=\"val_hawkes_hyperparams.csv\")\n",
    "# Hawkes processes simulations\n",
    "val_simulated_events_seqs = hawkes_simulations(val_mu, val_alpha, val_beta, filename='val_hawkes_simulations.csv')\n",
    "# Discrétiser les processus de Hawkes\n",
    "val_discret_simulated_events_seqs = discretise(val_simulated_events_seqs, filename='val_binned_hawkes_simulations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing dataset generation\n",
    "\n",
    "# Intensity Decay Parameter (β) = U(p = 1, q = 3)\n",
    "# Branching Ratio (η) = U(a = 0.05, b = 0.8)\n",
    "# Expected Activity (E) = 500\n",
    "# Time Horizon (T) = 100\n",
    "# Interval Length (∆) = 1\n",
    "# Testing processes = 20_000\n",
    "\n",
    "# Hawkes process hyper-parameters generation\n",
    "test_params, test_alpha, test_beta, test_mu = hyper_params_simulation(filename=\"test_hawkes_hyperparams.csv\")\n",
    "# Hawkes processes simulations\n",
    "test_simulated_events_seqs = hawkes_simulations(test_mu, test_alpha, test_beta, filename='test_hawkes_simulations.csv')\n",
    "# Discrétiser les processus de Hawkes\n",
    "test_discret_simulated_events_seqs = discretise(test_simulated_events_seqs, filename='test_binned_hawkes_simulations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11 ms ± 276 µs per loop (mean ± std. dev. of 100 runs, 1,000 loops each)\n",
      "4.08 ms ± 245 µs per loop (mean ± std. dev. of 100 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from UTILS.utils import write_csv\n",
    "\n",
    "def discretise(jump_times: np.ndarray, filename: str = 'binned_hawkes_simulations.csv') -> np.ndarray:\n",
    "\n",
    "    # Computed bins number\n",
    "    num_bins = int(var.TIME_HORIZON // var.DISCRETISE_STEP)\n",
    "\n",
    "    # For each process (j), compute jump times histogram (h) using the intervals boundaries specified by the bins\n",
    "    counts = np.array(list(map(partial(lambda h: np.histogram(h, bins=np.linspace(0, var.TIME_HORIZON, num_bins + 1))[0]), jump_times)), dtype=np.float64)\n",
    "                                    \n",
    "    # Created ist of dictionaries representing the binned simulated event sequences\n",
    "    counts_list = list(map(partial(lambda _, row: {str(idx): x for idx, x in enumerate(row)}, range(var.TIME_HORIZON)), counts))\n",
    "\n",
    "    # Write the counts to a CSV file\n",
    "    write_csv(counts_list, filename=filename)\n",
    "\n",
    "    return counts\n",
    "    \n",
    "\n",
    "def discretise2(jump_times: np.ndarray, filename: str = 'binned_hawkes_simulations.csv') -> np.ndarray:\n",
    "\n",
    "    # Computed bins number\n",
    "    num_bins = int(var.TIME_HORIZON // var.DISCRETISE_STEP)\n",
    "\n",
    "    # Initialized an array of zeros with dimensions (number of processes, number of jumps per unit of time)\n",
    "    counts = np.zeros((len(jump_times), num_bins), dtype=np.float64)\n",
    "\n",
    "    # For each process (j), compute jump times histogram (h) using the intervals boundaries specified by the bins\n",
    "    for j, h in enumerate(jump_times):\n",
    "        counts[j], _ = np.histogram(h, bins=np.linspace(0, var.TIME_HORIZON, num_bins + 1))\n",
    "                                    \n",
    "    # Created ist of dictionaries representing the binned simulated event sequences\n",
    "    counts_list = list(map(partial(lambda _, row: {str(idx): x for idx, x in enumerate(row)}, range(var.TIME_HORIZON)), counts))\n",
    "\n",
    "    # Write the counts to a CSV file\n",
    "    write_csv(counts_list, filename=filename)\n",
    "\n",
    "    return counts\n",
    "\n",
    "%timeit -r 100 -n 1000 discretise(train_simulated_events_seqs)\n",
    "%timeit -r 100 -n 1000 discretise2(train_simulated_events_seqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
