{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Hawkes Process Estimation - Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from DL.mlp_model import MLPTrainer\n",
    "from VARIABLES import preprocessing_var as prep\n",
    "from HAWKES.hawkes import hawkes_simulations, hawkes_simulation\n",
    "from HAWKES.hyperparameters import hyper_params_simulation\n",
    "from HAWKES.discretisation import discretise\n",
    "from UTILS.utils import write_csv, write_parquet, read_parquet, timer\n",
    "from PREPROCESSING.dataset import split_data, create_datasets, create_data_loaders\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Validation/Testing dataset generation\n",
    "\n",
    "# Intensity Decay Parameter (β) = U(p = 1, q = 3)\n",
    "# Branching Ratio (η) = U(a = 0.05, b = 0.8)\n",
    "# Expected Activity (E) = 500\n",
    "# Time Horizon (T) = 100\n",
    "# Interval Length (∆) = 1\n",
    "# Number of processes = 160_000\n",
    "\n",
    "# Hawkes process hyper-parameters generation\n",
    "params, alpha, beta, mu = hyper_params_simulation(filename=\"hawkes_hyperparams.parquet\")\n",
    "\n",
    "# Hawkes processes simulations\n",
    "simulated_events_seqs = hawkes_simulations(alpha, beta, mu, filename='hawkes_simulations.parquet')\n",
    "\n",
    "# Discrétiser les processus de Hawkes\n",
    "discret_simulated_events_seqs = discretise(simulated_events_seqs, filename='binned_hawkes_simulations.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_parquet(\"binned_hawkes_simulations.parquet\")\n",
    "y = read_parquet('hawkes_hyperparams.parquet')\n",
    "\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = split_data(x, y.iloc[:, [0, 2]])\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(train_x, train_y, val_x, val_y, test_x, test_y)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, train_losses, val_losses, val_y_pred, val_eta, val_mu \u001b[39m=\u001b[39m MLPTrainer()\u001b[39m.\u001b[39;49mtrain_model(train_loader, val_loader, val_x)\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\Documents\\VAE_HAWKES_PROCESS_ESTIMATION\\CODE\\UTILS\\utils.py:315\u001b[0m, in \u001b[0;36mprofiling.<locals>.prof_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m         writer\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     \u001b[39m# No profiling\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\Documents\\VAE_HAWKES_PROCESS_ESTIMATION\\CODE\\DL\\mlp_model.py:260\u001b[0m, in \u001b[0;36mMLPTrainer.train_model\u001b[1;34m(self, train_loader, val_loader, val_x)\u001b[0m\n\u001b[0;32m    257\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39meval\u001b[39m\u001b[39m.\u001b[39mLOGDIRUN,\u001b[39m \u001b[39m\u001b[39meval\u001b[39m\u001b[39m.\u001b[39mRUN_NAME)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m \u001b[39m# Displayed model summary\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msummary_model())\n\u001b[0;32m    262\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_epochs), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Progress\u001b[39m\u001b[39m'\u001b[39m, colour\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    264\u001b[0m \n\u001b[0;32m    265\u001b[0m     \u001b[39m# Converged (Fitted) to optimal parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\Documents\\VAE_HAWKES_PROCESS_ESTIMATION\\CODE\\DL\\mlp_model.py:97\u001b[0m, in \u001b[0;36mMLPTrainer.summary_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummary_model\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     90\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m    Return summary of model architecture\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39m        str: Summary of model's architecture\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     summary(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, input_size\u001b[39m=\u001b[39;49m(mlp\u001b[39m.\u001b[39;49mINPUT_SIZE,),\n\u001b[0;32m     98\u001b[0m             batch_dim\u001b[39m=\u001b[39;49mprep\u001b[39m.\u001b[39;49mBATCH_SIZE, col_names\u001b[39m=\u001b[39;49mmlp\u001b[39m.\u001b[39;49mSUMMARY_COL_NAMES, device\u001b[39m=\u001b[39;49mprep\u001b[39m.\u001b[39;49mDEVICE, mode\u001b[39m=\u001b[39;49mmlp\u001b[39m.\u001b[39;49mSUMMARY_MODE, verbose\u001b[39m=\u001b[39;49mmlp\u001b[39m.\u001b[39;49mSUMMARY_VERBOSE)\n\u001b[0;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmlp\u001b[39m.\u001b[39mSUMMARY_MODEL\u001b[39m:\u001b[39;00m\u001b[39m^30\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Summary\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:215\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     device \u001b[39m=\u001b[39m get_device(model)\n\u001b[0;32m    211\u001b[0m validate_user_params(\n\u001b[0;32m    212\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    213\u001b[0m )\n\u001b[1;32m--> 215\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[0;32m    216\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[0;32m    219\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    220\u001b[0m )\n\u001b[0;32m    221\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:250\u001b[0m, in \u001b[0;36mprocess_input\u001b[1;34m(input_data, input_size, batch_dim, device, dtypes)\u001b[0m\n\u001b[0;32m    248\u001b[0m         dtypes \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mfloat] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(input_size)\n\u001b[0;32m    249\u001b[0m     correct_input_size \u001b[39m=\u001b[39m get_correct_input_sizes(input_size)\n\u001b[1;32m--> 250\u001b[0m     x \u001b[39m=\u001b[39m get_input_tensor(correct_input_size, batch_dim, dtypes, device)\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m x, correct_input_size\n",
      "File \u001b[1;32mc:\\Users\\Nicolas Girard\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:499\u001b[0m, in \u001b[0;36mget_input_tensor\u001b[1;34m(input_size, batch_dim, dtypes, device)\u001b[0m\n\u001b[0;32m    497\u001b[0m     input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m*\u001b[39msize)\n\u001b[0;32m    498\u001b[0m     \u001b[39mif\u001b[39;00m batch_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m         input_tensor \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39;49munsqueeze(dim\u001b[39m=\u001b[39;49mbatch_dim)\n\u001b[0;32m    500\u001b[0m     x\u001b[39m.\u001b[39mappend(input_tensor\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mtype(dtype))\n\u001b[0;32m    501\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 128)"
     ]
    }
   ],
   "source": [
    "model, train_losses, val_losses, val_y_pred, val_eta, val_mu = MLPTrainer().train_model(train_loader, val_loader, val_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
